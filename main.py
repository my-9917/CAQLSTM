import os
import torch
import logging
from datetime import datetime
import config
from src.data_loader import create_data_loaders
from src.models.model_factory import create_model
from src.training.trainer import Trainer
from src.utils.visualization import (
    plot_training_curves, plot_predictions, 
    plot_phase_space, plot_error_distribution, plot_predictions_vs_true
)
import wfdb
from src.utils.data_analysis import analyze_dataset
# import numpy as np

def setup_logging(results_dir):
    log_file = os.path.join(results_dir, 'training.log')
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.FileHandler(log_file), logging.StreamHandler()]
    )
    return logging.getLogger(__name__)

def main():
    # åˆ›å»ºç»“æœç›®å½•
    timestamp = datetime.now().strftime("%m%d_%H%M")
    results_dir = os.path.join(config.RESULTS_DIR, f"{config.MODEL_TYPE}_{config.DATASET_CONFIG['record_name']}_{timestamp}")
    model_dir = config.MODEL_DIR
    if not os.path.exists(results_dir): os.makedirs(results_dir)
    if not os.path.exists(model_dir): os.makedirs(model_dir)
    
    logger = setup_logging(results_dir)
    logger.info(f"å¼€å§‹è¿è¡Œ - æ¨¡å‹ç±»å‹: {config.MODEL_TYPE}")

     # --- æ–°å¢ï¼šæ•°æ®åˆ†æéƒ¨åˆ† ---
    raw_data_path = os.path.join('data/raw', config.DATASET_CONFIG['record_name'])
    if os.path.exists(raw_data_path + '.dat'):
        logger.info(f"æ­£åœ¨åŠ è½½åŸå§‹æ•°æ®è¿›è¡Œåˆ†æ: {raw_data_path}")
        record = wfdb.rdrecord(raw_data_path)
        raw_signal = record.p_signal[:, 0]
        fs = record.fs
        analyze_dataset(raw_signal, fs, results_dir)
    else:
        logger.warning(f"åŸå§‹æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°äº {raw_data_path}ï¼Œè·³è¿‡æ•°æ®åˆ†æã€‚è¯·å…ˆè¿è¡Œdata_processing.pyä¸‹è½½æ•°æ®ã€‚")

    # åŠ è½½æ•°æ®
    train_data_path = config.TRAIN_DATA_PATH
    val_data_path = config.VAL_DATA_PATH
    if not os.path.exists(train_data_path):
        logger.error(f"æ•°æ®æ–‡ä»¶ '{train_data_path}' ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ data_processing.py")
        return

    logger.info(f"æ­£åœ¨ä»ä»¥ä¸‹è·¯å¾„åŠ è½½æ•°æ®:\n  è®­ç»ƒé›†: {train_data_path}\n  éªŒè¯é›†: {val_data_path}")
    train_loader, val_loader = create_data_loaders(train_data_path, val_data_path, config.BATCH_SIZE, None)

    # åˆ›å»ºæ¨¡å‹
    model_config_dict = {'qlstm_config': config.QLSTM_CONFIG}
    model = create_model(config.MODEL_TYPE, model_config_dict)
    
    # è®­ç»ƒé…ç½®
    trainer_config = {
        'device': config.DEVICE,
        'epochs': config.EPOCHS,
        'training_config': config.TRAINING_CONFIG,
        'model_dir': model_dir,
        'model_type': config.MODEL_TYPE
    }

    # è®­ç»ƒæ¨¡å‹
    trainer = Trainer(model, trainer_config)
    train_losses, val_losses = trainer.train(train_loader, val_loader)

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    logger.info("ğŸ“ˆ æ­£åœ¨ç”Ÿæˆç»“æœå›¾è¡¨...")
    plot_training_curves(train_losses, val_losses, os.path.join(results_dir, 'training_curves.png'))
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œåç»­åˆ†æ
    best_model_path = os.path.join(config.MODEL_DIR, f"{config.MODEL_TYPE}_best.pth")
    if os.path.exists(best_model_path):
        model.load_state_dict(torch.load(best_model_path))
        device = torch.device(config.DEVICE)
        
        # è°ƒç”¨æ‰€æœ‰ç»˜å›¾å‡½æ•°
        plot_predictions(model, val_loader, device, os.path.join(results_dir, 'predictions.png'))
        plot_phase_space(model, val_loader, device, os.path.join(results_dir, 'phase_space.png'))
        plot_error_distribution(model, val_loader, device, os.path.join(results_dir, 'error_distribution.png'))
        plot_predictions_vs_true(model, val_loader, device, os.path.join(results_dir, 'predictions_vs_true.png'))
    
    logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ‰€æœ‰ç»“æœä¿å­˜åœ¨: {results_dir}")

if __name__ == "__main__":
    main()